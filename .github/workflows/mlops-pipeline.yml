name: MLOps Pipeline CI/CD

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'src/**'
      - 'config/**'
      - 'requirements.txt'
      - '.github/workflows/**'
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      pipeline_stages:
        description: 'Pipeline stages to run'
        required: false
        default: 'data_collection,data_processing,fine_tuning,evaluation'
        type: string
      force_rerun:
        description: 'Force re-run of all stages'
        required: false
        default: false
        type: boolean

env:
  PYTHON_VERSION: '3.9'
  PIP_CACHE_DIR: ~/.cache/pip

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-cov
    
    - name: Run tests
      run: |
        pytest tests/ -v --cov=src --cov-report=xml --cov-report=html
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  lint:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'
    
    - name: Install linting tools
      run: |
        python -m pip install --upgrade pip
        pip install flake8 black isort mypy
    
    - name: Run black (code formatting)
      run: |
        black --check --diff src/ tests/
    
    - name: Run isort (import sorting)
      run: |
        isort --check-only --diff src/ tests/
    
    - name: Run flake8 (linting)
      run: |
        flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics
    
    - name: Run mypy (type checking)
      run: |
        mypy src/ --ignore-missing-imports

  security-scan:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Run Bandit security scan
      uses: python-security/bandit-action@v1
      with:
        args: -r src/ -f json -o bandit-report.json
    
    - name: Upload Bandit results
      uses: actions/upload-artifact@v3
      with:
        name: bandit-security-report
        path: bandit-report.json

  data-pipeline:
    runs-on: ubuntu-latest
    needs: [test, lint, security-scan]
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Set up environment
      run: |
        mkdir -p data logs
        echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" >> $GITHUB_ENV
    
    - name: Run data collection
      run: |
        python -c "
        import asyncio
        from src.config.config_manager import ConfigManager
        from src.data_collection.web_scraper import WebScraper
        
        async def collect_data():
            config = ConfigManager()
            scraper = WebScraper(config.get_data_collection_config().get('web_scraping', {}))
            data = await scraper.scrape_ev_websites()
            print(f'Collected {len(data) if data else 0} data items')
        
        asyncio.run(collect_data())
        "
    
    - name: Upload collected data
      uses: actions/upload-artifact@v3
      with:
        name: collected-data
        path: data/collected/
        retention-days: 7

  model-training:
    runs-on: ubuntu-latest
    needs: data-pipeline
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Download collected data
      uses: actions/download-artifact@v3
      with:
        name: collected-data
        path: data/collected/
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Set up environment
      run: |
        mkdir -p data/processed logs
        echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" >> $GITHUB_ENV
    
    - name: Process data and create training set
      run: |
        python -c "
        import json
        from src.data_processing.data_processor import DataProcessor, ProcessingConfig
        
        # Load collected data
        with open('data/collected/web_data.json', 'r') as f:
            web_data = json.load(f)
        
        # Process data
        processor = DataProcessor(ProcessingConfig(), '${{ secrets.OPENAI_API_KEY }}')
        training_data = processor.process_collected_data(web_data)
        
        # Save processed data
        processor.save_processed_data('data/processed')
        print(f'Created {len(training_data)} training examples')
        "
    
    - name: Validate training data format
      run: |
        python -c "
        import json
        from pathlib import Path
        
        # Check JSONL format
        training_file = Path('data/processed/training_data.jsonl')
        if training_file.exists():
            with open(training_file, 'r') as f:
                lines = f.readlines()
                print(f'Training file has {len(lines)} lines')
                
                # Validate first few lines
                for i, line in enumerate(lines[:3]):
                    try:
                        data = json.loads(line.strip())
                        if 'messages' in data:
                            print(f'Line {i+1}: Valid format')
                        else:
                            print(f'Line {i+1}: Missing messages field')
                    except json.JSONDecodeError:
                        print(f'Line {i+1}: Invalid JSON')
        "
    
    - name: Upload training data
      uses: actions/upload-artifact@v3
      with:
        name: training-data
        path: data/processed/
        retention-days: 30

  model-evaluation:
    runs-on: ubuntu-latest
    needs: model-training
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Download training data
      uses: actions/download-artifact@v3
      with:
        name: training-data
        path: data/processed/
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Set up environment
      run: |
        mkdir -p data/benchmark data/evaluation logs
        echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" >> $GITHUB_ENV
    
    - name: Create benchmark and evaluate
      run: |
        python -c "
        from src.evaluation.model_evaluator import ModelEvaluator, EvaluationConfig
        
        # Create evaluator
        evaluator = ModelEvaluator('${{ secrets.OPENAI_API_KEY }}', EvaluationConfig())
        
        # Create benchmark
        benchmark = evaluator.create_domain_benchmark()
        print(f'Benchmark created: {benchmark}')
        
        # Evaluate baseline model
        evaluation = evaluator.evaluate_models()
        print(f'Evaluation completed: {evaluation}')
        "
    
    - name: Upload evaluation results
      uses: actions/upload-artifact@v3
      with:
        name: evaluation-results
        path: |
          data/benchmark/
          data/evaluation/
        retention-days: 30

  deploy:
    runs-on: ubuntu-latest
    needs: model-evaluation
    if: github.event_name == 'workflow_dispatch' && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Download artifacts
      uses: actions/download-artifact@v3
      with:
        name: evaluation-results
        path: data/
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Deploy to staging
      run: |
        echo "Deploying to staging environment..."
        # Add your deployment logic here
        # This could include:
        # - Deploying to cloud platform
        # - Updating model registry
        # - Starting inference server
    
    - name: Run smoke tests
      run: |
        echo "Running smoke tests..."
        # Add your smoke test logic here
        # This could include:
        # - Health check endpoints
        # - Basic model inference
        # - API endpoint validation

  notify:
    runs-on: ubuntu-latest
    needs: [deploy]
    if: always()
    
    steps:
    - name: Notify on success
      if: needs.deploy.result == 'success'
      run: |
        echo "Pipeline completed successfully!"
        # Add notification logic (Slack, email, etc.)
    
    - name: Notify on failure
      if: needs.deploy.result == 'failure'
      run: |
        echo "Pipeline failed!"
        # Add failure notification logic
